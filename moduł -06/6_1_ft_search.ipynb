{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_1_ft_search.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hY8mCYhXU1vp"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjZrpTcGiY_w",
        "outputId": "45dd98ed-abee-4f61-9a8e-55e66b0fa8c5"
      },
      "source": [
        "!pip install gdown\n",
        "\n",
        "# Kolekcja ponad 100 tys. nagłówków z polskich portali informacyjnych z października-listopada 2020 r.\n",
        "!rm news_pl.jsonl\n",
        "!gdown https://drive.google.com/uc?id=1w8sx3Rs2W1fZgSnJmsKKph0oHueH0yww"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.10)\n",
            "rm: cannot remove 'news_pl.jsonl': No such file or directory\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w8sx3Rs2W1fZgSnJmsKKph0oHueH0yww\n",
            "To: /content/news_pl.jsonl\n",
            "42.7MB [00:01, 24.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvSJeYx1fzaE",
        "outputId": "6ece4cab-eb6e-4c69-d820-f6e04aec0fb3"
      },
      "source": [
        "# Wczytujemy dokumenty jako listę słowników. Każdy wiersz to jeden dokument.\n",
        "\n",
        "import json \n",
        "\n",
        "\n",
        "def read_json_documents(jsonl):\n",
        "    docs = []\n",
        "    with open(jsonl,'r') as file:\n",
        "        for line in file:\n",
        "            if(len(line.strip())>0):\n",
        "                docs.append(json.loads(line))\n",
        "    return docs\n",
        "\n",
        "\n",
        "headlines_pl = read_json_documents('news_pl.jsonl')\n",
        "print(len(headlines_pl))\n",
        "print(headlines_pl[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116056\n",
            "{'id': '81d72ff3d226249c001dd3515a413a60', 'language': 'pl', 'source': 'wirtualnemedia.pl', 'published': '2020-10-01T00:00:00Z', 'title': 'Aleksandra Budka po 8 latach rozstaje się z radiową Trójką', 'url': 'https://www.wirtualnemedia.pl/artykul/aleksandra-budka-po-8-latach-rozstaje-sie-z-radiowa-trojka', 'category': ['news']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUJqGQsOfzaJ",
        "outputId": "73316b8f-23f8-4a3d-e7dc-8540a0acacda"
      },
      "source": [
        "# 500 tys. artykułów z polskiej Wikipedii\n",
        "!rm wiki_pl.jsonl.gz\n",
        "!rm wiki_pl.jsonl\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1go0J35NtymB-cdogrLM3YyTsyCMCMPw0\n",
        "!gunzip wiki_pl.jsonl.gz\n",
        "\n",
        "wiki_docs = read_json_documents('wiki_pl.jsonl')\n",
        "\n",
        "print(len(wiki_docs))\n",
        "print(wiki_docs[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'wiki_pl.jsonl.gz': No such file or directory\n",
            "rm: cannot remove 'wiki_pl.jsonl': No such file or directory\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1go0J35NtymB-cdogrLM3YyTsyCMCMPw0\n",
            "To: /content/wiki_pl.jsonl.gz\n",
            "25.5MB [00:00, 33.3MB/s]\n",
            "500000\n",
            "{'id': '931674', 'title': 'Garnizony Armii Radzieckiej na terytorium Polski', 'category': ['Północna_Grupa_Wojsk_Armii_Radzieckiej', 'Garnizony_wojska_rosyjskiego', 'III_Rzeczpospolita', 'Stosunki_polsko-sowieckie', 'Stosunki_polsko-rosyjskie'], 'language': 'pl', 'published': '2016-01-01T02:57:20Z', 'url': 'https://pl.wikipedia.org/wiki/Garnizony Armii Radzieckiej na terytorium Polski'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcqsDL2mfzaJ",
        "outputId": "a11056db-cd1c-4b6e-e297-40c70441cb37"
      },
      "source": [
        "# Przeszukiwanie sekwencyjne 'brute-force'\n",
        "\n",
        "def bf_search(documents, strings):\n",
        "    matching_docs = []\n",
        "    for doc in documents:\n",
        "        for s in strings:\n",
        "            if s in doc['title']:\n",
        "                matching_docs.append(doc)\n",
        "    print(\"\\n---------------------------\\nTotal documents found: {}\\n---------------------------\\n\"\n",
        "          .format(len(matching_docs)))\n",
        "            \n",
        "    return matching_docs\n",
        "def print_docs(documents, fields):\n",
        "\n",
        "    for di, document in enumerate(documents):\n",
        "        print(\"{}. {}\\t{}\".format(di+1, *([document[f] for f in fields])))\n",
        "\n",
        "matching = bf_search(documents = headlines_pl,strings=['samolot'])\n",
        "print_docs(matching[:5], ['id','title'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------\n",
            "Total documents found: 107\n",
            "---------------------------\n",
            "\n",
            "1. e50d4cc63e508bba38d9d125b3ded190\tWrocław: 36 hiszpańskich studentów z koronawirusem. Przylecieli jednym samolotem\n",
            "2. ec4498474b4a4d0e893ece67045d9ed2\tChora na nowotwór wyruszyła na leczenie rządowym samolotem\n",
            "3. 01e5965aa2a2a1da9925345eed4bd5df\t18-letnia Julia poleciała do USA rządowym samolotem. \"Jesteśmy z Tobą!\"\n",
            "4. 0843f4d8a46fc11f96c99c8b0af0b5a0\tKoronawirus. 41-letnia Polka zatrzymana na lotnisku Schiphol. Gryzła i kopała załogę samolotu\n",
            "5. f271eedb333a5f86f3a276afd3064e4c\tKoniec latania \"na wypasie\". Przygotujcie się na cięcia kosztów i niewygody w samolotach\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hc5ASCtfzaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10a575d-ca10-4153-af11-9517634c9312"
      },
      "source": [
        "# Lematyzacja dokumentów w SpaCy\n",
        "# !pip install -U spacy\n",
        "# !python -m spacy validate\n",
        "# \n",
        "!pip install spacy-nightly --pre\n",
        "!python -m spacy download pl_core_news_sm\n",
        "\n",
        "\n",
        "import spacy\n",
        "nlp_pl = spacy.load(\"pl_core_news_sm\")\n",
        "\n",
        "doc = nlp_pl(headlines_pl[0]['title'])\n",
        "print([w.lemma_ for w in doc])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/f8/cc7abc80adbe5f6bdced56a7e0aa4d10abccb74ea9373e5a0c65a8723414/spacy_nightly-3.0.0rc2-cp36-cp36m-manylinux2014_x86_64.whl (11.0MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (3.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (20.8)\n",
            "Collecting pytokenizations\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/4d/14c0592544689defe9793240cb0e0e8e870c18bfc2dbd1e4170b96c73f89/pytokenizations-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (4.41.1)\n",
            "Collecting pathy\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/24/714fa97240ef8be3d0ce33cc5956db02d964635de96699fe63207ffd1660/pathy-0.3.4-py3-none-any.whl\n",
            "Collecting srsly<3.0.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/2c/f349f9423d83cde4610899f18b3eed621e59f62f395d954038a6014869b2/srsly-2.3.2-cp36-cp36m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 36.9MB/s \n",
            "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Collecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/48/5c/493a2f3bb0eac17b1d48129ecfd251f0520b6c89493e9fd0522f534a9e4a/catalogue-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (51.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (0.8.0)\n",
            "Collecting pydantic<1.7.0,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/5f/855412ad12817ae87f1c77d3af2fc384eaed3adfb8f3994816d75483fa20/pydantic-1.6.1-cp36-cp36m-manylinux2014_x86_64.whl (8.7MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (0.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (2.11.2)\n",
            "Collecting thinc<8.1.0,>=8.0.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/4d/2e636d9dec34101299f1545d1d3a39f2aec7dfc9af645079c6836ff9278c/thinc-8.0.0rc3-cp36-cp36m-manylinux2014_x86_64.whl (984kB)\n",
            "\u001b[K     |████████████████████████████████| 993kB 33.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly) (1.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->spacy-nightly) (2.4.7)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 41.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses<1.0,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pathy->spacy-nightly) (0.8)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages (from typer<0.4.0,>=0.3.0->spacy-nightly) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy-nightly) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy-nightly) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy-nightly) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->spacy-nightly) (1.1.1)\n",
            "Collecting contextvars<3,>=2.4; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: smart-open, contextvars\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp36-none-any.whl size=107097 sha256=93a531adfc8733fb76d92935165e7287bb7a0121e0d4af95ec85353eab82b4d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7667 sha256=392413f4eda11d282b59bcea628c43af02c474a7c6dcba6bc7a2c64418f755d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built smart-open contextvars\n",
            "\u001b[31mERROR: thinc 8.0.0rc3 has requirement pydantic<1.8.0,>=1.7.1, but you'll have pydantic 1.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement catalogue<1.1.0,>=0.0.7, but you'll have catalogue 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement srsly<1.1.0,>=1.0.2, but you'll have srsly 2.3.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement thinc==7.4.0, but you'll have thinc 8.0.0rc3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pytokenizations, smart-open, typer, pathy, srsly, catalogue, pydantic, immutables, contextvars, thinc, spacy-nightly\n",
            "  Found existing installation: smart-open 4.1.0\n",
            "    Uninstalling smart-open-4.1.0:\n",
            "      Successfully uninstalled smart-open-4.1.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "Successfully installed catalogue-2.0.1 contextvars-2.4 immutables-0.14 pathy-0.3.4 pydantic-1.6.1 pytokenizations-0.7.2 smart-open-3.0.0 spacy-nightly-3.0.0rc2 srsly-2.3.2 thinc-8.0.0rc3 typer-0.3.2\n",
            "2021-01-17 09:32:23.453849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Collecting pl_core_news_sm==3.0.0a0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_sm-3.0.0a0/pl_core_news_sm-3.0.0a0.tar.gz (56.9MB)\n",
            "\u001b[K     |████████████████████████████████| 56.9MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy-nightly<3.1.0,>=3.0.0a41 in /usr/local/lib/python3.6/dist-packages (from pl_core_news_sm==3.0.0a0) (3.0.0rc2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (0.4.1)\n",
            "Requirement already satisfied: pydantic<1.7.0,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (1.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2.11.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2.0.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (3.0.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (3.3.0)\n",
            "Requirement already satisfied: pytokenizations in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (0.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (20.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (51.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2.23.0)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (0.3.2)\n",
            "Requirement already satisfied: pathy in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (0.8.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.0rc0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (8.0.0rc3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (1.0.5)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic<1.7.0,>=1.5.0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (3.0.4)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages (from typer<0.4.0,>=0.3.0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pathy->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (3.0.0)\n",
            "Requirement already satisfied: contextvars<3,>=2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.0rc0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (2.4)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars<3,>=2.4; python_version < \"3.7\"->thinc<8.1.0,>=8.0.0rc0->spacy-nightly<3.1.0,>=3.0.0a41->pl_core_news_sm==3.0.0a0) (0.14)\n",
            "Building wheels for collected packages: pl-core-news-sm\n",
            "  Building wheel for pl-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pl-core-news-sm: filename=pl_core_news_sm-3.0.0a0-cp36-none-any.whl size=56922786 sha256=1cfff96794b09ed8f03b5e67163de138b0e29f25277ced39c9e2f8c9d20296b5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8p0__9ji/wheels/d4/13/08/3ac2fa0c43ba1fc807e6ef3be19560496175c61de51c79f7d2\n",
            "Successfully built pl-core-news-sm\n",
            "Installing collected packages: pl-core-news-sm\n",
            "Successfully installed pl-core-news-sm-3.0.0a0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pl_core_news_sm')\n",
            "['Aleksander', 'Budek', 'po', '8', 'rok', 'rozstawać', 'się', 'z', 'radiowy', 'trójka']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgNNOyIjfzaK",
        "outputId": "9734de91-1c04-4701-ba29-f722f80a8e43"
      },
      "source": [
        "# Najprostszy odwrócony indeks z lematyzacją\n",
        "\n",
        "\n",
        "def get_inv_index(documents):\n",
        "    index = {}\n",
        "    matching_docs = []\n",
        "    for d in documents:\n",
        "        doc = nlp_pl(d['title'])\n",
        "        for w in doc:\n",
        "            if w.lemma_ in index:\n",
        "                index[w.lemma_].append(d)\n",
        "            else:\n",
        "                index[w.lemma_]=[d]\n",
        "        \n",
        "    return index\n",
        "\n",
        "\n",
        "inverted_index = get_inv_index(headlines_pl[:10])\n",
        "\n",
        "for lemma in inverted_index:\n",
        "    if len(inverted_index[lemma]) > 1:\n",
        "        print(\"{} ({})\\t{}\".format(lemma, len(inverted_index[lemma]), [d['title'] for d in inverted_index[lemma]]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z (2)\t['Aleksandra Budka po 8 latach rozstaje się z radiową Trójką', 'Gabriela Łazarczyk odchodzi z \"Gazety Wyborczej\"']\n",
            ". (2)\t['Senat odrzucił sprawozdanie KRRiT za 2019 r. i informację o działalności Rady Mediów Narodowych', 'Xiaomi przedstawia smartfony Mi10T. Ekrany 6,67 cala i wydajne procesory w cenie od 249 do 649 euro']\n",
            "i (3)\t['Senat odrzucił sprawozdanie KRRiT za 2019 r. i informację o działalności Rady Mediów Narodowych', 'Xiaomi przedstawia smartfony Mi10T. Ekrany 6,67 cala i wydajne procesory w cenie od 249 do 649 euro', 'Trzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno']\n",
            "medium (2)\t['Senat odrzucił sprawozdanie KRRiT za 2019 r. i informację o działalności Rady Mediów Narodowych', 'Redaktorzy mediów niezależnych na Białorusi: trwa czystka przestrzeni medialnej']\n",
            "nowy (2)\t['Nowy serial „Król” od 6 listopada w Canal+ (oficjalny zwiastun)', 'Trzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno']\n",
            "od (2)\t['Nowy serial „Król” od 6 listopada w Canal+ (oficjalny zwiastun)', 'Xiaomi przedstawia smartfony Mi10T. Ekrany 6,67 cala i wydajne procesory w cenie od 249 do 649 euro']\n",
            "w (6)\t['Nowy serial „Król” od 6 listopada w Canal+ (oficjalny zwiastun)', 'Tomasz Jankowski rzecznikiem prasowym Zarządu Zasobu Komunalnego we Wrocławiu', 'Xiaomi przedstawia smartfony Mi10T. Ekrany 6,67 cala i wydajne procesory w cenie od 249 do 649 euro', 'Trzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno', 'Trzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno', 'Rynek ekologicznych kosmetyków w Polsce wart niemal 200 milionów złotych']\n",
            "na (2)\t['Technologia 5G dostępna także dla abonentów Plusa na Kartę', 'Redaktorzy mediów niezależnych na Białorusi: trwa czystka przestrzeni medialnej']\n",
            "\" (2)\t['Gabriela Łazarczyk odchodzi z \"Gazety Wyborczej\"', 'Gabriela Łazarczyk odchodzi z \"Gazety Wyborczej\"']\n",
            "play (2)\t['Trzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno', 'Trzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno']\n",
            "now (2)\t['Trzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno', 'Trzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IXy_fTyfzaL",
        "outputId": "a669cb6f-4337-4842-8218-718c1361cf19"
      },
      "source": [
        "# Wyszukiwanie w odwróconym indeksie\n",
        "\n",
        "# Indeksowanie\n",
        "inverted_index = get_inv_index(headlines_pl[:1000])\n",
        "print(\"Distinct lemmas: {}.\".format(len(inverted_index)))\n",
        "\n",
        "# Normalizacja zapytania\n",
        "user_query = 'media'\n",
        "doc = nlp_pl(user_query)\n",
        "print([w.lemma_ for w in doc])\n",
        "\n",
        "\n",
        "# 'Wyszukiwanie' \n",
        "for lemma in [w.lemma_ for w in doc]:\n",
        "    print(inverted_index[lemma])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distinct lemmas: 3594.\n",
            "['medium']\n",
            "[{'id': 'a289227a9701294ee5cee628e7dd267e', 'language': 'pl', 'source': 'wirtualnemedia.pl', 'published': '2020-10-01T00:00:00Z', 'title': 'Senat odrzucił sprawozdanie KRRiT za 2019 r. i informację o działalności Rady Mediów Narodowych', 'url': 'https://www.wirtualnemedia.pl/artykul/senat-odrzucil-sprawozdanie-krrit-za-2019-r-i-informacje-o-dzialalnosci-rady-mediow-narodowych', 'category': ['news']}, {'id': 'cff0c0a0641efbe21a0a55e9efc5c96d', 'language': 'pl', 'source': 'wirtualnemedia.pl', 'published': '2020-10-01T00:00:00Z', 'title': 'Redaktorzy mediów niezależnych na Białorusi: trwa czystka przestrzeni medialnej', 'url': 'https://www.wirtualnemedia.pl/artykul/redaktorzy-mediow-niezaleznych-na-bialorusi-trwa-czystka-przestrzeni-medialnej', 'category': ['news']}, {'id': 'abe71863651df31a9cc76f61834781a3', 'language': 'pl', 'source': 'newsweek.pl', 'published': '2020-10-01T00:00:00Z', 'title': 'Jarosław, śmielej! Prawicowe media wzywają obóz władzy do zaostrzenia kursu', 'url': 'https://www.newsweek.pl/opinie/jaroslaw-smielej-prawicowe-media-wzywaja-oboz-wladzy-do-zaostrzenia-kursu/71v7jlg', 'category': ['news']}, {'id': '0e2ff6935f33bde08b482d30f4d2d6a7', 'language': 'pl', 'source': 'gazetawroclawska.pl', 'published': '2020-10-01T00:00:00Z', 'title': 'Bayern wywalczył Superpuchar, ale niemieckie media surowo oceniły Robera Lewandowskiego: \"Tym razem niewiele pokazał z supergwiazdy\"', 'url': 'https://polskatimes.pl/bayern-wywalczyl-superpuchar-ale-niemieckie-media-surowo-ocenily-robera-lewandowskiego-tym-razem-niewiele-pokazal-z-supergwiazdy/ar/c2-15208626', 'category': ['news']}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3W6LopHfzaL",
        "outputId": "5f2af5d3-33d9-4414-9551-f29f327225f7"
      },
      "source": [
        "# Odwrócony indeks nazw własnych?\n",
        "doc = nlp_pl('Magazyn śledczy Anity Gargas')\n",
        "print([w.lemma_ for w in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Anita gargas']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc8TwrQTRFId"
      },
      "source": [
        "## Apache Solr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bjzM87qUj2J"
      },
      "source": [
        "## Instalacja w Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhM9i9SPfzaM",
        "outputId": "c47b0c9e-a1e4-4211-f21f-cd50425f8386"
      },
      "source": [
        "# Sprawdźmy wersję JAVA VM \n",
        "\n",
        "!java -version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.9.1\" 2020-11-04\n",
            "OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHQaFavsfzaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672d44ec-df98-4cb8-aa6c-9c70b6d4d3f4"
      },
      "source": [
        "# Pobieramy katalog z konfiguracją indeksów news_pl i wiki_pl\n",
        "\n",
        "!rm solr-preconf.tar.gz\n",
        "!gdown https://drive.google.com/uc?id=1CUFilOS3raMmLkzEQeXW2PHxxZF2iusF\n",
        "!tar -zxf solr-preconf.tar.gz\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'solr-preconf.tar.gz': No such file or directory\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CUFilOS3raMmLkzEQeXW2PHxxZF2iusF\n",
            "To: /content/solr-preconf.tar.gz\n",
            "201MB [00:05, 40.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RkqA6AjT6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ef9df5-6923-4857-ae31-7ddd248cba5c"
      },
      "source": [
        "# Pobieramy i rozpakowujemy aktualną wersję Solra \n",
        "\n",
        "!rm -rf solr-8.7.0\n",
        "!wget https://apache.mirrors.tworzy.net/lucene/solr/8.7.0/solr-8.7.0.tgz \n",
        "!tar -zxf  solr-8.7.0.tgz \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-19 06:39:46--  https://apache.mirrors.tworzy.net/lucene/solr/8.7.0/solr-8.7.0.tgz\n",
            "Resolving apache.mirrors.tworzy.net (apache.mirrors.tworzy.net)... 51.83.241.43\n",
            "Connecting to apache.mirrors.tworzy.net (apache.mirrors.tworzy.net)|51.83.241.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 200805960 (192M) [application/x-gzip]\n",
            "Saving to: ‘solr-8.7.0.tgz’\n",
            "\n",
            "solr-8.7.0.tgz      100%[===================>] 191.50M  11.4MB/s    in 26s     \n",
            "\n",
            "2021-01-19 06:40:13 (7.37 MB/s) - ‘solr-8.7.0.tgz’ saved [200805960/200805960]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0sr0uiU0o-B",
        "outputId": "0767b154-36f4-43fd-c557-57d1921bdc2c"
      },
      "source": [
        "# Zatrzymujemy ew. działające instancje\n",
        "\n",
        "!/content/solr-8.7.0/bin/solr stop -all\n",
        "#!ps -ef | grep solr\n",
        "#!kill -9 PID\n",
        "\n",
        "# Startujemy instancję\n",
        "!/content/solr-8.7.0/bin/solr start -force\n",
        "\n",
        "# Kopiujemy konfigurację indeksów z folderów:\n",
        "\n",
        "!/content/solr-8.7.0/bin/solr create_core  -force -c news_pl -d ./solr-preconf/server/solr/news_pl \n",
        "!curl 'http://localhost:8983/solr/admin/cores?action=RELOAD&core=news_pl'\n",
        "\n",
        "!/content/solr-8.7.0/bin/solr create_core  -force -c wiki_pl -d ./solr-preconf/server/solr/wiki_pl \n",
        "!curl 'http://localhost:8983/solr/admin/cores?action=RELOAD&core=wiki_pl'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Waiting up to 180 seconds to see Solr running on port 8983 [|]  \b\b\b\b\b\b [/]  \b\b\b\b\b\b [-]  \b\b\b\b\b\b [\\]  \b\b\b\b\b\b [|]  \b\b\b\b\b\b [/]  \b\b\b\b\b\b [-]  \b\b\b\b\b\b [\\]  \b\b\b\b\b\b [|]  \b\b\b\b\b\b [/]  \b\b\b\b\b\b [-]  \b\b\b\b\b\b [\\]  \b\b\b\b\b\b [|]  \b\b\b\b\b\b [/]  \n",
            "Started Solr server on port 8983 (pid=197). Happy searching!\n",
            "\n",
            "\b\b\b\b\b\b    \b\b\b\b\n",
            "Created new core 'news_pl'\n",
            "{\n",
            "  \"responseHeader\":{\n",
            "    \"status\":0,\n",
            "    \"QTime\":691}}\n",
            "\n",
            "Created new core 'wiki_pl'\n",
            "{\n",
            "  \"responseHeader\":{\n",
            "    \"status\":0,\n",
            "    \"QTime\":448}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AGdjY1yS3YN",
        "outputId": "8036cad3-f29c-429b-e6b4-49a47d0f206d"
      },
      "source": [
        "# Sprawdźmy, czy utworzyły się indeksy\n",
        "\n",
        "!curl http://localhost:8983/solr/admin/cores\n",
        "\n",
        "# W wersji uruchamianej lokalnie oba indeksy powinny być również widoczne w konsoli: http://localhost:8983/solr/#/ "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"responseHeader\":{\n",
            "    \"status\":0,\n",
            "    \"QTime\":23},\n",
            "  \"initFailures\":{},\n",
            "  \"status\":{\n",
            "    \"news_pl\":{\n",
            "      \"name\":\"news_pl\",\n",
            "      \"instanceDir\":\"/content/solr-8.7.0/server/solr/news_pl\",\n",
            "      \"dataDir\":\"/content/solr-8.7.0/server/solr/news_pl/data/\",\n",
            "      \"config\":\"solrconfig.xml\",\n",
            "      \"schema\":\"schema.xml\",\n",
            "      \"startTime\":\"2021-01-19T06:40:34.426Z\",\n",
            "      \"uptime\":8425,\n",
            "      \"index\":{\n",
            "        \"numDocs\":0,\n",
            "        \"maxDoc\":0,\n",
            "        \"deletedDocs\":0,\n",
            "        \"indexHeapUsageBytes\":0,\n",
            "        \"version\":2,\n",
            "        \"segmentCount\":0,\n",
            "        \"current\":true,\n",
            "        \"hasDeletions\":false,\n",
            "        \"directory\":\"org.apache.lucene.store.NRTCachingDirectory:NRTCachingDirectory(MMapDirectory@/content/solr-8.7.0/server/solr/news_pl/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@1dd89a68; maxCacheMB=48.0 maxMergeSizeMB=4.0)\",\n",
            "        \"segmentsFile\":\"segments_1\",\n",
            "        \"segmentsFileSizeInBytes\":69,\n",
            "        \"userData\":{},\n",
            "        \"sizeInBytes\":69,\n",
            "        \"size\":\"69 bytes\"}},\n",
            "    \"wiki_pl\":{\n",
            "      \"name\":\"wiki_pl\",\n",
            "      \"instanceDir\":\"/content/solr-8.7.0/server/solr/wiki_pl\",\n",
            "      \"dataDir\":\"/content/solr-8.7.0/server/solr/wiki_pl/data/\",\n",
            "      \"config\":\"solrconfig.xml\",\n",
            "      \"schema\":\"schema.xml\",\n",
            "      \"startTime\":\"2021-01-19T06:40:37.975Z\",\n",
            "      \"uptime\":4894,\n",
            "      \"index\":{\n",
            "        \"numDocs\":0,\n",
            "        \"maxDoc\":0,\n",
            "        \"deletedDocs\":0,\n",
            "        \"indexHeapUsageBytes\":0,\n",
            "        \"version\":2,\n",
            "        \"segmentCount\":0,\n",
            "        \"current\":true,\n",
            "        \"hasDeletions\":false,\n",
            "        \"directory\":\"org.apache.lucene.store.NRTCachingDirectory:NRTCachingDirectory(MMapDirectory@/content/solr-8.7.0/server/solr/wiki_pl/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@1dd89a68; maxCacheMB=48.0 maxMergeSizeMB=4.0)\",\n",
            "        \"segmentsFile\":\"segments_1\",\n",
            "        \"segmentsFileSizeInBytes\":69,\n",
            "        \"userData\":{},\n",
            "        \"sizeInBytes\":69,\n",
            "        \"size\":\"69 bytes\"}}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY8mCYhXU1vp"
      },
      "source": [
        "### Użycie Solr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VYPJkZyfzaN"
      },
      "source": [
        "# Metody do indeksowania dokumentów przez HTTP w uprzednio zdefiniowanym schemacie indeksu Solr\n",
        "\n",
        "import json\n",
        "import requests\n",
        "\n",
        "def index_documents(solr_url, docs):\n",
        "    bytes = json.dumps(docs).encode(encoding='UTF-8')\n",
        "    if(len(docs)> 0):\n",
        "        bytes = json.dumps(docs).encode(encoding='UTF-8')\n",
        "        try:\n",
        "            res = requests.post(url=solr_url+'/update/json/docs',\n",
        "                                data=bytes,\n",
        "                                headers={'Content-Type': 'application/octet-stream'})\n",
        "            solr_url+'update?commit=true'\n",
        "            print(\"Update response: {}\".format(res))\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "def index_by_batch(solr_url, docs, batch_size):\n",
        "    print(\"USING CORE: {}\" .format(solr_url))\n",
        "    doc_buffer=[]\n",
        "    for doci, doc in enumerate(docs):\n",
        "        doc_buffer.append(doc)\n",
        "        if len(doc_buffer)%batch_size==0:\n",
        "            index_documents(solr_url = solr_url, docs=doc_buffer)\n",
        "            print('Adding doc {} to index'.format(doci+1))\n",
        "            doc_buffer.clear()\n",
        "    print('Adding doc {} to index'.format(doci+1))\n",
        "    index_documents(solr_url = solr_url, docs=doc_buffer)\n",
        "    print('Done indexing.'.format(doci+1))\n",
        "    \n",
        "    requests.get(solr_url +'/update?commit=true')\n",
        " \n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-InNXFxqfzaN"
      },
      "source": [
        "def delete_all_documents(solr_url):\n",
        "    \"\"\"\n",
        "    Wywołanie równoważne z:\n",
        "    !curl \"http://localhost:8983/solr/news_pl/update?commit=true\" -H \"Content-Type: text/xml\" --data-binary '<delete><query>*:*</query></delete>'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(solr_url+'/update?commit=true')\n",
        "        res = requests.get(url=solr_url+'/update?commit=true',\n",
        "                                data='<delete><query>*:*</query></delete>'.encode(encoding='UTF-8'),\n",
        "                                headers={'Content-Type': 'text/xml'})\n",
        "        print(res)\n",
        "    except Exception as e:\n",
        "        print(str(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N732XSdfzaN",
        "outputId": "557b6d9c-f618-4424-c28d-d991f2023d72"
      },
      "source": [
        "# Przykłady indeksowania dokumentów    \n",
        "\n",
        "doc1 = {'id':'136f7046b8c9bf01ba3d3fd331180b79', \n",
        "        'language':'pl', \n",
        "        'source':'dziennik.pl',\n",
        "        'published':'2011-01-23T18:31:00Z',\n",
        "        'category':['news'],\n",
        "        'title':'Tajemnicza historia chińskiego niewidzialnego samolotu', \n",
        "        'url':'https://wiadomosci.dziennik.pl/swiat/artykuly/318888,tajemnicza-historia-chinskiego-niewidzialnego-samolotu.html'\n",
        "       }\n",
        "\n",
        "# Opcjonalnie możemy najpierw usunąć wszystkie dokumenty\n",
        "print(\"Clearing the index...\")\n",
        "\n",
        "s_url = 'http://localhost:8983/solr/news_pl'\n",
        "delete_all_documents(solr_url = s_url)\n",
        "\n",
        "# Dodajemy testowo 1 dokument:\n",
        "index_by_batch(solr_url = s_url, docs=[doc1], batch_size=10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing the index...\n",
            "http://localhost:8983/solr/news_pl/update?commit=true\n",
            "<Response [200]>\n",
            "USING CORE: http://localhost:8983/solr/news_pl\n",
            "Adding doc 1 to index\n",
            "Update response: <Response [200]>\n",
            "Done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQf629P9fzaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39adc25e-3458-4bec-dad3-412f6bb88a00"
      },
      "source": [
        "# Dodajemy ponad 100 tys. dokumentów\n",
        "\n",
        "delete_all_documents(solr_url = s_url)\n",
        "headlines_pl = read_json_documents('news_pl.jsonl')\n",
        "print(\"Headlines to index {}.\".format(len(headlines_pl)))\n",
        "\n",
        "index_by_batch(solr_url=s_url, docs = headlines_pl, batch_size=10000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://localhost:8983/solr/news_pl/update?commit=true\n",
            "<Response [200]>\n",
            "Headlines to index 116056.\n",
            "USING CORE: http://localhost:8983/solr/news_pl\n",
            "Update response: <Response [200]>\n",
            "Adding doc 10000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 20000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 30000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 40000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 50000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 60000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 70000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 80000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 90000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 100000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 110000 to index\n",
            "Adding doc 116056 to index\n",
            "Update response: <Response [200]>\n",
            "Done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP-KLuyzfzaO"
      },
      "source": [
        "#Przykłady odpytywania indeksu z poziomu Pythona \n",
        "\n",
        "\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import json\n",
        "s_url = 'http://localhost:8983/solr/news_pl'\n",
        "\n",
        "def print_response(response, fields=['id','title','score']):\n",
        "    print(\"\\n{}\\nTotal documents found: {}\\n{}\\n\"\n",
        "          .format('-'*25,response['response']['numFound'],'-'*25))\n",
        "    # Print the name of each document.\n",
        "    for di, document in enumerate(response['response']['docs']):\n",
        "        print(\"{}. {}\\t{}\\t{}\".format(di+1, *([document[f] for f in fields])))\n",
        "        \n",
        "    if 'facet_counts' in response:\n",
        "        print(\"\\n FACETS: \\n\")\n",
        "        print(response['facet_counts']['facet_fields'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF--wcwSfzaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb3c630-f3b6-4784-fca4-1e84ffbfe806"
      },
      "source": [
        "# 1. Proste zapytanie o 10 dokumentów zawierających dowolną formę słowa 'samolot'\n",
        "connection = urlopen(s_url+'/select?q=title:samolot&wt=json&rows=10&fl=*,score')\n",
        "response = json.load(connection)\n",
        "print_response(response=response, fields=['source','title','score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------\n",
            "Total documents found: 128\n",
            "-------------------------\n",
            "\n",
            "1. wnp.pl\tCzas na mniejsze samoloty?\t4.300211\n",
            "2. interia.pl\tStworzył własny samolot elektryczny\t4.300211\n",
            "3. wnp.pl\tNieszczepieni samolotem nie polecą\t4.300211\n",
            "4. tvp.info\tKraksa samolotów. Pięć osób zginęło\t4.1164083\n",
            "5. wnp.pl\tLufthansa uziemi jeszcze więcej samolotów\t4.1164083\n",
            "6. interia.pl\tNiezidentyfikowany samolot zauważony nad Kalifornią\t4.1164083\n",
            "7. onet.pl\tAwaryjne lądowanie samolotu AN-124\t4.1164083\n",
            "8. onet.pl\tAwaryjne lądowanie samolotu AN-124\t4.1164083\n",
            "9. polsatnews.pl\tZderzenie samolotów we Francji. Są ofiary\t3.9476738\n",
            "10. tvp.info\tNiemieccy mechanicy odmówili serwisu samolotu Łukaszenki\t3.9476738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsDDLk4MfzaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430ed59a-4d7f-468d-8487-4f1f9b14f80d"
      },
      "source": [
        "# Składnia DisMax\n",
        "# https://lucene.apache.org/solr/guide/8_7/the-dismax-query-parser.html\n",
        "\n",
        "import urllib\n",
        "\n",
        "# 1.Zapytanie o 10 dokumentów zawierających dowolną formę słowa 'samolot' lub 'lotniczy'\n",
        "connection = urlopen(\n",
        "    s_url+'/select?q='\n",
        "    + urllib.request.quote('title:samolot OR title:lotniczy')\n",
        "    +'&wt=json&rows=10&fl=*,score')\n",
        "response = json.load(connection)\n",
        "print_response(response=response, fields=['source','title','score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------\n",
            "Total documents found: 235\n",
            "-------------------------\n",
            "\n",
            "1. gazeta.pl\tSamoloty wracają nad Wisłę. Lotniczy pokaz dla upamiętnienia 102. rocznicy odzyskania niepodległości\t6.3987446\n",
            "2. polsatnews.pl\tNajdłuższe połączenie lotnicze świata wraca do rozkładu lotów. Samoloty pokonają ponad 15 tys. km\t6.003709\n",
            "3. tvn24.pl\tDo samolotu wejdą tylko zaszczepieni. To pierwsza linia lotnicza, która zdecydowała się na taki krok\t5.823934\n",
            "4. wp.pl\tSzczepionka na COVID warunkiem wejścia na pokład samolotu? Pierwsza linia lotnicza zdecydowała się na taki krok\t5.654613\n",
            "5. dzienniklodzki.pl\tKoronawirus. Szczepienie może być wymagane do lotu samolotem. Linia Qantas to pierwsza linia lotnicza, która zdecydowała się na taki krok\t5.0655265\n",
            "6. wnp.pl\tCzas na mniejsze samoloty?\t4.300211\n",
            "7. interia.pl\tStworzył własny samolot elektryczny\t4.300211\n",
            "8. wnp.pl\tNieszczepieni samolotem nie polecą\t4.300211\n",
            "9. tvp.info\tKraksa samolotów. Pięć osób zginęło\t4.1164083\n",
            "10. wnp.pl\tLufthansa uziemi jeszcze więcej samolotów\t4.1164083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHwQXmH6fzaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5e0233-26d5-4610-d8b6-dcb28c024360"
      },
      "source": [
        "# Wzbogacanie indeksu o jednostki nazewnicze (Zob. Moduł 6.4)\n",
        "\n",
        "import spacy\n",
        "nlp_pl = spacy.load(\"pl_core_news_sm\")\n",
        "\n",
        "def annotate_documents(documents):\n",
        "    for di, d in enumerate(documents):\n",
        "        doc = nlp_pl(d[\"title\"])\n",
        "        named_ents=[\"{}___{}\".format(w.lemma_, w.label_) for w in doc.ents]\n",
        "        if len(named_ents) > 0:\n",
        "           d[\"ents\"]=named_ents\n",
        "           d[\"ent_types\"]=[w.label_ for w in doc.ents]\n",
        "        if((di)%1000 == 0):\n",
        "            print(\"Annotated {} of {} documents.\".format(di+1,len(documents)))\n",
        "    return documents\n",
        "\n",
        "headlines_pl = read_json_documents('news_pl.jsonl')\n",
        "print(\"Headlines to index {}.\".format(len(headlines_pl)))\n",
        "\n",
        "annotated_headlines = annotate_documents(headlines_pl[0:10])\n",
        "\n",
        "for ah in annotated_headlines:\n",
        "  if 'ents' in ah:\n",
        "    print(\"{}\\t{}\\n\".format(ah['ents'], ah['title']))\n",
        "\n",
        "#s_url = 'http://localhost:8983/solr/news_pl'\n",
        "#delete_all_documents(solr_url = s_url)\n",
        "\n",
        "# Dodajemy testowo 1 dokument:\n",
        "#index_by_batch(solr_url = s_url, docs=[doc1], batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headlines to index 116056.\n",
            "Annotated 1 of 10 documents.\n",
            "['Aleksander Budek___persName', 'trójka___orgName']\tAleksandra Budka po 8 latach rozstaje się z radiową Trójką\n",
            "\n",
            "['senat___orgName', 'krrit___orgName', '2019 r .___date', 'rada medium narodowy___orgName']\tSenat odrzucił sprawozdanie KRRiT za 2019 r. i informację o działalności Rady Mediów Narodowych\n",
            "\n",
            "['6 listopad___date', 'canal+___placeName']\tNowy serial „Król” od 6 listopada w Canal+ (oficjalny zwiastun)\n",
            "\n",
            "['plusa___orgName']\tTechnologia 5G dostępna także dla abonentów Plusa na Kartę\n",
            "\n",
            "['Białoruś___placeName']\tRedaktorzy mediów niezależnych na Białorusi: trwa czystka przestrzeni medialnej\n",
            "\n",
            "['Gabriel łazarczyk___persName', '\" gazeta wyborczy \"___orgName']\tGabriela Łazarczyk odchodzi z \"Gazety Wyborczej\"\n",
            "\n",
            "['tomasz jankowski___persName', 'zarząd zasobu komunalnego w Wrocław___orgName']\tTomasz Jankowski rzecznikiem prasowym Zarządu Zasobu Komunalnego we Wrocławiu\n",
            "\n",
            "['play now i play now tv___orgName', 'październik___date']\tTrzy nowe kanały w Play Now i Play Now TV, w październiku otwarte okno\n",
            "\n",
            "['Polska___placeName']\tRynek ekologicznych kosmetyków w Polsce wart niemal 200 milionów złotych\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToW3aphrfzaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ad51c8-8ab0-4548-b04b-d267d7848328"
      },
      "source": [
        "# Reindeksujemy dokumenty\n",
        "\n",
        "annotated_headlines = annotate_documents(headlines_pl[0:500000])\n",
        "\n",
        "s_url = 'http://localhost:8983/solr/news_pl'\n",
        "\n",
        "delete_all_documents(solr_url = s_url)\n",
        "print(\"Headlines to index {}.\".format(len(annotated_headlines)))\n",
        "\n",
        "index_by_batch(solr_url=s_url, docs = annotated_headlines, batch_size=10000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Annotated 1 of 116056 documents.\n",
            "Annotated 1001 of 116056 documents.\n",
            "Annotated 2001 of 116056 documents.\n",
            "Annotated 3001 of 116056 documents.\n",
            "Annotated 4001 of 116056 documents.\n",
            "Annotated 5001 of 116056 documents.\n",
            "Annotated 6001 of 116056 documents.\n",
            "Annotated 7001 of 116056 documents.\n",
            "Annotated 8001 of 116056 documents.\n",
            "Annotated 9001 of 116056 documents.\n",
            "Annotated 10001 of 116056 documents.\n",
            "Annotated 11001 of 116056 documents.\n",
            "Annotated 12001 of 116056 documents.\n",
            "Annotated 13001 of 116056 documents.\n",
            "Annotated 14001 of 116056 documents.\n",
            "Annotated 15001 of 116056 documents.\n",
            "Annotated 16001 of 116056 documents.\n",
            "Annotated 17001 of 116056 documents.\n",
            "Annotated 18001 of 116056 documents.\n",
            "Annotated 19001 of 116056 documents.\n",
            "Annotated 20001 of 116056 documents.\n",
            "Annotated 21001 of 116056 documents.\n",
            "Annotated 22001 of 116056 documents.\n",
            "Annotated 23001 of 116056 documents.\n",
            "Annotated 24001 of 116056 documents.\n",
            "Annotated 25001 of 116056 documents.\n",
            "Annotated 26001 of 116056 documents.\n",
            "Annotated 27001 of 116056 documents.\n",
            "Annotated 28001 of 116056 documents.\n",
            "Annotated 29001 of 116056 documents.\n",
            "Annotated 30001 of 116056 documents.\n",
            "Annotated 31001 of 116056 documents.\n",
            "Annotated 32001 of 116056 documents.\n",
            "Annotated 33001 of 116056 documents.\n",
            "Annotated 34001 of 116056 documents.\n",
            "Annotated 35001 of 116056 documents.\n",
            "Annotated 36001 of 116056 documents.\n",
            "Annotated 37001 of 116056 documents.\n",
            "Annotated 38001 of 116056 documents.\n",
            "Annotated 39001 of 116056 documents.\n",
            "Annotated 40001 of 116056 documents.\n",
            "Annotated 41001 of 116056 documents.\n",
            "Annotated 42001 of 116056 documents.\n",
            "Annotated 43001 of 116056 documents.\n",
            "Annotated 44001 of 116056 documents.\n",
            "Annotated 45001 of 116056 documents.\n",
            "Annotated 46001 of 116056 documents.\n",
            "Annotated 47001 of 116056 documents.\n",
            "Annotated 48001 of 116056 documents.\n",
            "Annotated 49001 of 116056 documents.\n",
            "Annotated 50001 of 116056 documents.\n",
            "Annotated 51001 of 116056 documents.\n",
            "Annotated 52001 of 116056 documents.\n",
            "Annotated 53001 of 116056 documents.\n",
            "Annotated 54001 of 116056 documents.\n",
            "Annotated 55001 of 116056 documents.\n",
            "Annotated 56001 of 116056 documents.\n",
            "Annotated 57001 of 116056 documents.\n",
            "Annotated 58001 of 116056 documents.\n",
            "Annotated 59001 of 116056 documents.\n",
            "Annotated 60001 of 116056 documents.\n",
            "Annotated 61001 of 116056 documents.\n",
            "Annotated 62001 of 116056 documents.\n",
            "Annotated 63001 of 116056 documents.\n",
            "Annotated 64001 of 116056 documents.\n",
            "Annotated 65001 of 116056 documents.\n",
            "Annotated 66001 of 116056 documents.\n",
            "Annotated 67001 of 116056 documents.\n",
            "Annotated 68001 of 116056 documents.\n",
            "Annotated 69001 of 116056 documents.\n",
            "Annotated 70001 of 116056 documents.\n",
            "Annotated 71001 of 116056 documents.\n",
            "Annotated 72001 of 116056 documents.\n",
            "Annotated 73001 of 116056 documents.\n",
            "Annotated 74001 of 116056 documents.\n",
            "Annotated 75001 of 116056 documents.\n",
            "Annotated 76001 of 116056 documents.\n",
            "Annotated 77001 of 116056 documents.\n",
            "Annotated 78001 of 116056 documents.\n",
            "Annotated 79001 of 116056 documents.\n",
            "Annotated 80001 of 116056 documents.\n",
            "Annotated 81001 of 116056 documents.\n",
            "Annotated 82001 of 116056 documents.\n",
            "Annotated 83001 of 116056 documents.\n",
            "Annotated 84001 of 116056 documents.\n",
            "Annotated 85001 of 116056 documents.\n",
            "Annotated 86001 of 116056 documents.\n",
            "Annotated 87001 of 116056 documents.\n",
            "Annotated 88001 of 116056 documents.\n",
            "Annotated 89001 of 116056 documents.\n",
            "Annotated 90001 of 116056 documents.\n",
            "Annotated 91001 of 116056 documents.\n",
            "Annotated 92001 of 116056 documents.\n",
            "Annotated 93001 of 116056 documents.\n",
            "Annotated 94001 of 116056 documents.\n",
            "Annotated 95001 of 116056 documents.\n",
            "Annotated 96001 of 116056 documents.\n",
            "Annotated 97001 of 116056 documents.\n",
            "Annotated 98001 of 116056 documents.\n",
            "Annotated 99001 of 116056 documents.\n",
            "Annotated 100001 of 116056 documents.\n",
            "Annotated 101001 of 116056 documents.\n",
            "Annotated 102001 of 116056 documents.\n",
            "Annotated 103001 of 116056 documents.\n",
            "Annotated 104001 of 116056 documents.\n",
            "Annotated 105001 of 116056 documents.\n",
            "Annotated 106001 of 116056 documents.\n",
            "Annotated 107001 of 116056 documents.\n",
            "Annotated 108001 of 116056 documents.\n",
            "Annotated 109001 of 116056 documents.\n",
            "Annotated 110001 of 116056 documents.\n",
            "Annotated 111001 of 116056 documents.\n",
            "Annotated 112001 of 116056 documents.\n",
            "Annotated 113001 of 116056 documents.\n",
            "Annotated 114001 of 116056 documents.\n",
            "Annotated 115001 of 116056 documents.\n",
            "Annotated 116001 of 116056 documents.\n",
            "http://localhost:8983/solr/news_pl/update?commit=true\n",
            "<Response [200]>\n",
            "Headlines to index 116056.\n",
            "USING CORE: http://localhost:8983/solr/news_pl\n",
            "Update response: <Response [200]>\n",
            "Adding doc 10000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 20000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 30000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 40000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 50000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 60000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 70000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 80000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 90000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 100000 to index\n",
            "Update response: <Response [200]>\n",
            "Adding doc 110000 to index\n",
            "Adding doc 116056 to index\n",
            "Update response: <Response [200]>\n",
            "Done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3EWxqT5fzaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828cff18-d11c-4fc6-80df-76a176f72bd7"
      },
      "source": [
        "# Zapytanie o tytuły zawierające nazwę miejsca\n",
        "\n",
        "import urllib\n",
        "\n",
        "# 1.Zapytanie o 10 dokumentów zawierających dowolną formę słowa 'samolot' a zarazem nazwę miejsca\n",
        "connection = urlopen(\n",
        "    s_url+'/select?q='\n",
        "    + urllib.request.quote('title:samolot AND ent_types:placeName')\n",
        "    +'&wt=json&rows=10&fl=*,score')\n",
        "response = json.load(connection)\n",
        "print_response(response=response, fields=['source','title','score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------\n",
            "Total documents found: 41\n",
            "-------------------------\n",
            "\n",
            "1. polsatnews.pl\tZderzenie samolotów we Francji. Są ofiary\t4.3692303\n",
            "2. tvp.info\tNiemieccy mechanicy odmówili serwisu samolotu Łukaszenki\t4.3692303\n",
            "3. naszdziennik.pl\tMazowieckie: Awaryjne lądowanie samolotu w Modlinie\t4.3692303\n",
            "4. wp.pl\tFrancja. Zderzenie dwóch małych samolotów. Są ofiary\t4.213784\n",
            "5. polsatnews.pl\tAwantura na pokładzie samolotu. Polka pobiła współpasażerki\t4.213784\n",
            "6. interia.pl\tCzeskie samoloty morskie dla polskiej Straży Granicznej\t4.213784\n",
            "7. interia.pl\tAwaryjne lądowanie samolotu na lotnisku w Modlinie\t4.213784\n",
            "8. interia.pl\tCzeskiej produkcji samoloty już strzegą polskich granic\t4.213784\n",
            "9. onet.pl\tUSA. Szamotanina na pokładzie samolotu. Poszło o maseczkę\t4.070116\n",
            "10. polsatnews.pl\tAwaryjne lądowanie samolotu w Modlinie. Problemy z podwoziem\t4.070116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6yU5woGfzaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3d19c1-c32e-4830-b5f8-ba22dfddad1e"
      },
      "source": [
        "# Zapytanie o tytuły zawierające nazwę miejsca\n",
        "\n",
        "import urllib\n",
        "\n",
        "# 1.Zapytanie o 10 dokumentów zawierających wzmianki osób zaczynające się od ciągu 'Gabriel'\n",
        "connection = urlopen(\n",
        "    s_url+'/select?q='\n",
        "    + urllib.request.quote('ents:Gabriel*___persName')\n",
        "    +'&wt=json&rows=10&fl=*,score')\n",
        "response = json.load(connection)\n",
        "print_response(response=response, fields=['source','title','score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------\n",
            "Total documents found: 14\n",
            "-------------------------\n",
            "\n",
            "1. wirtualnemedia.pl\tGabriela Łazarczyk odchodzi z \"Gazety Wyborczej\"\t1.0\n",
            "2. interia.pl\tGabriela Morawska-Stanecka o nowym ministrze edukacji: Skandaliczna nominacja\t1.0\n",
            "3. kobieta.wp.pl\tGabrielę pasjonują perfumy. Ma 250 flakonów i zdradza, jak dobrać idealny zapach\t1.0\n",
            "4. press.pl\tGabriela Dworniak przestała kierować Agencją Kreacji Rozrywki i Oprawy TVP\t1.0\n",
            "5. rp.pl\tGabriela Morawska-Stanecka: Wyrok TK wynika z tchórzostwa\t1.0\n",
            "6. interia.pl\tRafał i Gabriel z \"Królowych życia\" zostali okradzeni\t1.0\n",
            "7. plotek.pl\t\"Królowe życia\". Rafał i Gabriel zostali okradzeni. \"Nie mieliśmy jak wejść do domu\"\t1.0\n",
            "8. interia.pl\tRafał i Gabriel z \"Królowych życia\" zostali okradzeni! Przeżyli dramat!\t1.0\n",
            "9. gazeta.pl\tAktywistka Gabriela Lazarek spędziła noc \"na dołku\". Wyszła z poważnymi zarzutami\t1.0\n",
            "10. plotek.pl\t\"Królowe życia\". Dagmara Kaźmierska kpi ze związku Gabriela i Rafała: \"To jest gorsze od tego, czym ja się zajmowałam\"\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhe6C-xkfzaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce564df-841b-4548-96c8-a29d2186c92a"
      },
      "source": [
        "# Agregacja wszystkich pasujących dokumentów po typach nazw własnych\n",
        "\n",
        "import urllib\n",
        "\n",
        "# 1.Zapytanie o 5 dokumentów zawierających lemat 'Brazylia'\n",
        "connection = urlopen(\n",
        "    s_url+'/select?q='\n",
        "    + urllib.request.quote('title:brazylia')\n",
        "    +'&wt=json&rows=5&fl=*,score'\n",
        "    +'&facet.field=ent_types&facet=on')\n",
        "response = json.load(connection)\n",
        "print_response(response=response, fields=['source','title','ents'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------\n",
            "Total documents found: 112\n",
            "-------------------------\n",
            "\n",
            "1. tvn24.pl\tAmbasador odwołana z Brazylii\t['Brazylia___placeName']\n",
            "2. interia.pl\tBrazylia: Znaczny spadek przyrostu zakażeń\t['brazylia___persName']\n",
            "3. rp.pl\tMinister zdrowia Brazylii zakażony koronawirusem\t['Brazylia___placeName']\n",
            "4. tvn24.pl\tNie ma mocnych na Brazylię\t['Brazylia___persName']\n",
            "5. wnp.pl\tBrazylia: 27 750 nowych przypadków koronawirusa\t['brazylia___persName']\n",
            "\n",
            " FACETS: \n",
            "\n",
            "{'ent_types': ['persName', 82, 'placeName', 42, 'orgName', 7, 'geogName', 3, 'date', 0, 'time', 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}