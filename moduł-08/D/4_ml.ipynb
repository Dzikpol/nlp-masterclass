{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"klej_polemo2.0-in/train.tsv\", \"r\") as f:\n",
    "    raw_train = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"klej_polemo2.0-in/dev.tsv\", \"r\") as f:\n",
    "    raw_dev = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(raw_data):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    for doc in raw_data:\n",
    "        text, target = doc.strip().split(\"\\t\")\n",
    "        if \"plus\" in target:\n",
    "            label = 0\n",
    "        elif \"minus\" in target:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 2\n",
    "        corpus.append(text)\n",
    "        labels.append(label)\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "train_corpus, train_labels = prepare_data(raw_train[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_corpus, test_labels = prepare_data(raw_dev[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVM + słownik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pl_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "senti_df = pd.read_csv(\"slownikWydzwieku01.csv\", sep=\"\\t\", header=None)\n",
    "senti_dict = senti_df[[0, 4]].set_index(0).to_dict()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'aby',\n",
       " 'ach',\n",
       " 'acz',\n",
       " 'aczkolwiek',\n",
       " 'aj',\n",
       " 'albo',\n",
       " 'ale',\n",
       " 'alez',\n",
       " 'ależ',\n",
       " 'ani',\n",
       " 'az',\n",
       " 'aż',\n",
       " 'bardziej',\n",
       " 'bardzo',\n",
       " 'beda',\n",
       " 'bede',\n",
       " 'bedzie',\n",
       " 'bez',\n",
       " 'bo',\n",
       " 'bowiem',\n",
       " 'by',\n",
       " 'byc',\n",
       " 'byl',\n",
       " 'byla',\n",
       " 'byli',\n",
       " 'bylo',\n",
       " 'byly',\n",
       " 'bynajmniej',\n",
       " 'być',\n",
       " 'był',\n",
       " 'była',\n",
       " 'było',\n",
       " 'były',\n",
       " 'będzie',\n",
       " 'będą',\n",
       " 'będę',\n",
       " 'cala',\n",
       " 'cali',\n",
       " 'caly',\n",
       " 'cała',\n",
       " 'cały',\n",
       " 'ci',\n",
       " 'cie',\n",
       " 'ciebie',\n",
       " 'cię',\n",
       " 'co',\n",
       " 'cokolwiek',\n",
       " 'cos',\n",
       " 'coś',\n",
       " 'czasami',\n",
       " 'czasem',\n",
       " 'czemu',\n",
       " 'czy',\n",
       " 'czyli',\n",
       " 'daleko',\n",
       " 'deda',\n",
       " 'dla',\n",
       " 'dlaczego',\n",
       " 'dlatego',\n",
       " 'do',\n",
       " 'dobrze',\n",
       " 'dokad',\n",
       " 'dokąd',\n",
       " 'dosc',\n",
       " 'dość',\n",
       " 'duzo',\n",
       " 'dużo',\n",
       " 'dwa',\n",
       " 'dwaj',\n",
       " 'dwie',\n",
       " 'dwoje',\n",
       " 'dzis',\n",
       " 'dzisiaj',\n",
       " 'dziś',\n",
       " 'gdy',\n",
       " 'gdyby',\n",
       " 'gdyz',\n",
       " 'gdyż',\n",
       " 'gdzie',\n",
       " 'gdziekolwiek',\n",
       " 'gdzies',\n",
       " 'gdzieś',\n",
       " 'go',\n",
       " 'i',\n",
       " 'ich',\n",
       " 'ile',\n",
       " 'im',\n",
       " 'inna',\n",
       " 'inne',\n",
       " 'inny',\n",
       " 'innych',\n",
       " 'iz',\n",
       " 'iż',\n",
       " 'ja',\n",
       " 'jak',\n",
       " 'jakas',\n",
       " 'jakaś',\n",
       " 'jakby',\n",
       " 'jaki',\n",
       " 'jakichs',\n",
       " 'jakichś',\n",
       " 'jakie',\n",
       " 'jakis',\n",
       " 'jakiz',\n",
       " 'jakiś',\n",
       " 'jakiż',\n",
       " 'jakkolwiek',\n",
       " 'jako',\n",
       " 'jakos',\n",
       " 'jakoś',\n",
       " 'je',\n",
       " 'jeden',\n",
       " 'jedna',\n",
       " 'jednak',\n",
       " 'jednakze',\n",
       " 'jednakże',\n",
       " 'jedno',\n",
       " 'jego',\n",
       " 'jej',\n",
       " 'jemu',\n",
       " 'jesli',\n",
       " 'jest',\n",
       " 'jestem',\n",
       " 'jeszcze',\n",
       " 'jezeli',\n",
       " 'jeśli',\n",
       " 'jeżeli',\n",
       " 'juz',\n",
       " 'już',\n",
       " 'ją',\n",
       " 'kazdy',\n",
       " 'każdy',\n",
       " 'kiedy',\n",
       " 'kilka',\n",
       " 'kims',\n",
       " 'kimś',\n",
       " 'kto',\n",
       " 'ktokolwiek',\n",
       " 'ktora',\n",
       " 'ktore',\n",
       " 'ktorego',\n",
       " 'ktorej',\n",
       " 'ktory',\n",
       " 'ktorych',\n",
       " 'ktorym',\n",
       " 'ktorzy',\n",
       " 'ktos',\n",
       " 'ktoś',\n",
       " 'która',\n",
       " 'które',\n",
       " 'którego',\n",
       " 'której',\n",
       " 'który',\n",
       " 'których',\n",
       " 'którym',\n",
       " 'którzy',\n",
       " 'ku',\n",
       " 'lat',\n",
       " 'lecz',\n",
       " 'lub',\n",
       " 'ma',\n",
       " 'mają',\n",
       " 'mam',\n",
       " 'mało',\n",
       " 'mi',\n",
       " 'miedzy',\n",
       " 'mimo',\n",
       " 'między',\n",
       " 'mna',\n",
       " 'mnie',\n",
       " 'mną',\n",
       " 'moga',\n",
       " 'mogą',\n",
       " 'moi',\n",
       " 'moim',\n",
       " 'moj',\n",
       " 'moja',\n",
       " 'moje',\n",
       " 'moze',\n",
       " 'mozliwe',\n",
       " 'mozna',\n",
       " 'może',\n",
       " 'możliwe',\n",
       " 'można',\n",
       " 'mu',\n",
       " 'musi',\n",
       " 'my',\n",
       " 'mój',\n",
       " 'na',\n",
       " 'nad',\n",
       " 'nam',\n",
       " 'nami',\n",
       " 'nas',\n",
       " 'nasi',\n",
       " 'nasz',\n",
       " 'nasza',\n",
       " 'nasze',\n",
       " 'naszego',\n",
       " 'naszych',\n",
       " 'natomiast',\n",
       " 'natychmiast',\n",
       " 'nawet',\n",
       " 'nia',\n",
       " 'nic',\n",
       " 'nich',\n",
       " 'nie',\n",
       " 'niech',\n",
       " 'niego',\n",
       " 'niej',\n",
       " 'niemu',\n",
       " 'nigdy',\n",
       " 'nim',\n",
       " 'nimi',\n",
       " 'niz',\n",
       " 'nią',\n",
       " 'niż',\n",
       " 'no',\n",
       " 'o',\n",
       " 'obok',\n",
       " 'od',\n",
       " 'około',\n",
       " 'on',\n",
       " 'ona',\n",
       " 'one',\n",
       " 'oni',\n",
       " 'ono',\n",
       " 'oraz',\n",
       " 'oto',\n",
       " 'owszem',\n",
       " 'pan',\n",
       " 'pana',\n",
       " 'pani',\n",
       " 'po',\n",
       " 'pod',\n",
       " 'podczas',\n",
       " 'pomimo',\n",
       " 'ponad',\n",
       " 'poniewaz',\n",
       " 'ponieważ',\n",
       " 'powinien',\n",
       " 'powinna',\n",
       " 'powinni',\n",
       " 'powinno',\n",
       " 'poza',\n",
       " 'prawie',\n",
       " 'przeciez',\n",
       " 'przecież',\n",
       " 'przed',\n",
       " 'przede',\n",
       " 'przedtem',\n",
       " 'przez',\n",
       " 'przy',\n",
       " 'roku',\n",
       " 'rowniez',\n",
       " 'również',\n",
       " 'sam',\n",
       " 'sama',\n",
       " 'sie',\n",
       " 'się',\n",
       " 'skad',\n",
       " 'skąd',\n",
       " 'soba',\n",
       " 'sobie',\n",
       " 'sobą',\n",
       " 'sposob',\n",
       " 'sposób',\n",
       " 'swoje',\n",
       " 'są',\n",
       " 'ta',\n",
       " 'tak',\n",
       " 'taka',\n",
       " 'taki',\n",
       " 'takie',\n",
       " 'takze',\n",
       " 'także',\n",
       " 'tam',\n",
       " 'te',\n",
       " 'tego',\n",
       " 'tej',\n",
       " 'ten',\n",
       " 'teraz',\n",
       " 'też',\n",
       " 'to',\n",
       " 'toba',\n",
       " 'tobie',\n",
       " 'tobą',\n",
       " 'totez',\n",
       " 'toteż',\n",
       " 'totobą',\n",
       " 'trzeba',\n",
       " 'tu',\n",
       " 'tutaj',\n",
       " 'twoi',\n",
       " 'twoim',\n",
       " 'twoj',\n",
       " 'twoja',\n",
       " 'twoje',\n",
       " 'twym',\n",
       " 'twój',\n",
       " 'ty',\n",
       " 'tych',\n",
       " 'tylko',\n",
       " 'tym',\n",
       " 'u',\n",
       " 'w',\n",
       " 'wam',\n",
       " 'wami',\n",
       " 'was',\n",
       " 'wasz',\n",
       " 'wasza',\n",
       " 'wasze',\n",
       " 'we',\n",
       " 'według',\n",
       " 'wiele',\n",
       " 'wielu',\n",
       " 'więc',\n",
       " 'więcej',\n",
       " 'wlasnie',\n",
       " 'wszyscy',\n",
       " 'wszystkich',\n",
       " 'wszystkie',\n",
       " 'wszystkim',\n",
       " 'wszystko',\n",
       " 'wtedy',\n",
       " 'wy',\n",
       " 'właśnie',\n",
       " 'z',\n",
       " 'za',\n",
       " 'zaden',\n",
       " 'zadna',\n",
       " 'zadne',\n",
       " 'zadnych',\n",
       " 'zapewne',\n",
       " 'zawsze',\n",
       " 'ze',\n",
       " 'zeby',\n",
       " 'zeznowu',\n",
       " 'znow',\n",
       " 'znowu',\n",
       " 'znów',\n",
       " 'zostal',\n",
       " 'został',\n",
       " 'zł',\n",
       " 'żaden',\n",
       " 'żadna',\n",
       " 'żadne',\n",
       " 'żadnych',\n",
       " 'że',\n",
       " 'żeby'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = set(pd.read_csv(\"https://raw.githubusercontent.com/bieli/stopwords/master/polish.stopwords.txt\", \n",
    "                            header=None).values[:,0])\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "doc_train_corpus = list(nlp.pipe(train_corpus, disable=[\"ner\"]))\n",
    "doc_test_corpus = list(nlp.pipe(test_corpus, disable=[\"ner\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "norm_train_corpus = [[token.lemma_ for token in doc if token.is_alpha and token.lemma_ not in stopwords] \n",
    "                     for doc in doc_train_corpus]\n",
    "norm_test_corpus = [[token.lemma_ for token in doc if token.is_alpha and token.lemma_ not in stopwords] \n",
    "                    for doc in doc_test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['super',\n",
       " 'lekarz',\n",
       " 'człowiek',\n",
       " 'duży',\n",
       " 'c',\n",
       " 'duży',\n",
       " 'doświadczenie',\n",
       " 'trafny',\n",
       " 'diagnoza',\n",
       " 'wielki',\n",
       " 'cierpliwość',\n",
       " 'człowiek',\n",
       " 'stary',\n",
       " 'rok',\n",
       " 'opiekować',\n",
       " 'mama',\n",
       " 'staruszka',\n",
       " 'twierdzić',\n",
       " 'mieć',\n",
       " 'duży',\n",
       " 'szczęście',\n",
       " 'mieć',\n",
       " 'lekarz',\n",
       " 'naprawdę',\n",
       " 'wiedzieć',\n",
       " 'cobyśmy',\n",
       " 'zrobić',\n",
       " 'doktor',\n",
       " 'dzięki',\n",
       " 'mama',\n",
       " 'żyć',\n",
       " 'wizyta',\n",
       " 'specjalista',\n",
       " 'konsultować',\n",
       " 'uważać',\n",
       " 'dobry',\n",
       " 'mieć',\n",
       " 'ograniczony',\n",
       " 'zaufanie',\n",
       " 'dobry',\n",
       " 'doktór',\n",
       " 'napisać',\n",
       " 'niestety',\n",
       " 'mieć',\n",
       " 'pacjent',\n",
       " 'przepracować',\n",
       " 'powód',\n",
       " 'obawiać',\n",
       " 'zdrowie',\n",
       " 'dostęp',\n",
       " 'trudny',\n",
       " 'możliwy']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x, \n",
    "                       ngram_range=(1, 2), max_df=0.9, min_df=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train = vect.fit_transform(norm_train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5783, 5223)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_test = vect.transform(norm_test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scores_train = [sum(senti_dict.get(token, 0) for token in doc) / len(doc) for doc in norm_train_corpus]\n",
    "scores_test = [sum(senti_dict.get(token, 0) for token in doc) / len(doc) for doc in norm_test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scores_train = csr_matrix(scores_train).T\n",
    "scores_test = csr_matrix(scores_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5783, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train_with_scores = hstack([X_train, scores_train])\n",
    "X_test_with_scores = hstack([X_test, scores_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(random_state=42, C=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.06, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_with_scores, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      1568\n",
      "           1       0.82      0.96      0.89      2194\n",
      "           2       0.92      0.75      0.83      2021\n",
      "\n",
      "    accuracy                           0.87      5783\n",
      "   macro avg       0.88      0.87      0.87      5783\n",
      "weighted avg       0.87      0.87      0.87      5783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_labels, svm.predict(X_train_with_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80       209\n",
      "           1       0.76      0.91      0.83       271\n",
      "           2       0.80      0.72      0.76       243\n",
      "\n",
      "    accuracy                           0.80       723\n",
      "   macro avg       0.81      0.79      0.80       723\n",
      "weighted avg       0.80      0.80      0.80       723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, svm.predict(X_test_with_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
