{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"klej_polemo2.0-in/train.tsv\", \"r\") as f:\n",
    "    raw_train = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"klej_polemo2.0-in/dev.tsv\", \"r\") as f:\n",
    "    raw_dev = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(raw_data):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    for doc in raw_data:\n",
    "        text, target = doc.strip().split(\"\\t\")\n",
    "        if \"plus\" in target:\n",
    "            label = 0\n",
    "        elif \"minus\" in target:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 2\n",
    "        corpus.append(text)\n",
    "        labels.append(label)\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "train_corpus, train_labels = prepare_data(raw_train[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_corpus, test_labels = prepare_data(raw_dev[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LSTM + słownik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vector-crawl/cc.pl.300.bin.gz\n",
    "!gunzip cc.pl.300.bin.gz\n",
    "!pip install fasttext\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import fasttext\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poddany</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>przewrażliwiony</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cudzoziemiec</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>przekonywać</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skrupuł</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0  1  2  3  4    5\n",
       "0          poddany  c  0 -1 -1 -4.6\n",
       "1  przewrażliwiony  m  1  1 -2 -3.6\n",
       "2     cudzoziemiec  c  0  0  0 -2.6\n",
       "3      przekonywać  m  1  1  0 -1.8\n",
       "4          skrupuł  c  1  1  1 -3.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_df = pd.read_csv(\"slownikWydzwieku01.csv\", sep=\"\\t\", header=None)\n",
    "senti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mins = np.min(senti_df[[2, 3, 4, 5]].values, axis=0)\n",
    "maxs = np.max(senti_df[[2, 3, 4, 5]].values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "senti_dict = {}\n",
    "for row in senti_df.itertuples(index=False):\n",
    "    key = row[0]\n",
    "    value = np.array(row[2:])\n",
    "    value = (value - mins) / (maxs - mins)\n",
    "    senti_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.25      , 0.26744186])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_dict[\"poddany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "VEX = fasttext.load_model(\"cc.pl.300.bin\")\n",
    "N_FEATS = VEX.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def w2v(token):\n",
    "    try:\n",
    "        return VEX.get_word_vector(token)\n",
    "    except KeyError:\n",
    "        return np.zeros((N_FEATS,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tok_train_corpus = [doc.split() for doc in train_corpus]\n",
    "tok_test_corpus = [doc.split() for doc in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_data = list(zip(tok_train_corpus, train_labels))\n",
    "test_data = list(zip(tok_test_corpus, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "PADDING_VECTOR = np.zeros((N_FEATS + 4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def datapoints_to_batch(datapoints, max_len, senti_dict):\n",
    "    size = len(datapoints)\n",
    "    vectors = []\n",
    "    lengths = []\n",
    "    labels = []\n",
    "    for tokens, label in datapoints:\n",
    "        vec = [np.concatenate((w2v(token), senti_dict.get(token, np.zeros(4)))) for token in tokens]\n",
    "        tok_num = len(vec)\n",
    "        if tok_num > max_len:\n",
    "            vec = vec[:max_len]\n",
    "            tok_num = max_len\n",
    "        vectors.append(vec)\n",
    "        lengths.append(tok_num)\n",
    "        labels.append(label)\n",
    "    max_len = max(lengths)\n",
    "    \n",
    "    for vec in vectors:\n",
    "        while len(vec) < max_len:\n",
    "            vec.insert(0, PADDING_VECTOR)\n",
    "    X = torch.tensor(vectors, dtype=torch.float32)\n",
    "    Y = torch.tensor(labels)\n",
    "    return X, Y, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train_on_batch(model, criterion, optimizer, X, Y, lengths):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X, lengths)\n",
    "    loss = criterion(output, Y)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict_on_batch(model, X, Y, lengths):\n",
    "    model.eval()\n",
    "    output = model(X, lengths)\n",
    "    decision = output.topk(1).indices.squeeze()\n",
    "    equal = decision == Y\n",
    "    correct = sum(equal).item()\n",
    "    return correct, decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.dense = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def init_state(self, batch_size):\n",
    "        state = torch.zeros(2, batch_size, self.hidden_size)\n",
    "        cell = torch.zeros(2, batch_size, self.hidden_size)\n",
    "        return state, cell\n",
    "    \n",
    "    def forward(self, data, lengths):\n",
    "        batch_size = data.shape[0]\n",
    "        zero_hidden, zero_cell = self.init_state(batch_size)\n",
    "        \n",
    "        packed_input = pack_padded_sequence(data, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input, (zero_hidden, zero_cell))\n",
    "        \n",
    "        output, lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        aggregated = self.dropout(output.sum(1).div(lengths.unsqueeze(1)))\n",
    "        \n",
    "        output = self.softmax(self.dense(aggregated))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = LSTMModel(N_FEATS + 4, 20, 3)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 10\n",
    "max_len = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "num_train_batches = len(train_data) // batch_size + int(bool(len(train_data) % batch_size))\n",
    "num_test_batches = len(test_data) // batch_size + int(bool(len(test_data) % batch_size))\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:56<00:00, 10.21it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:03, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 555.7316371202469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 18.13it/s]\n",
      "  0%|          | 0/579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 62.73972602739726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:55<00:00, 10.40it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:04, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 444.92512008547783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 18.13it/s]\n",
      "  0%|          | 1/579 [00:00<00:59,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 68.4931506849315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:56<00:00, 10.17it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:03, 19.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 395.9656071290374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.85it/s]\n",
      "  0%|          | 2/579 [00:00<00:56, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 71.78082191780823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:56<00:00, 10.25it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:04, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 372.0642773061991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.21it/s]\n",
      "  0%|          | 1/579 [00:00<01:02,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 69.17808219178082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:56<00:00, 10.26it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:03, 18.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 359.2016426771879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 18.16it/s]\n",
      "  0%|          | 2/579 [00:00<00:55, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 71.64383561643835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:56<00:00, 10.28it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:04, 17.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 349.8338042348623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.05it/s]\n",
      "  0%|          | 1/579 [00:00<01:03,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 75.89041095890411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:59<00:00,  9.71it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:04, 17.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 328.2367929816246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.19it/s]\n",
      "  0%|          | 1/579 [00:00<01:31,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.24657534246575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:58<00:00,  9.97it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:03, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 322.7046853899956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.79it/s]\n",
      "  0%|          | 1/579 [00:00<01:05,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 70.82191780821918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:55<00:00, 10.40it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:03, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 316.63884633406997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.84it/s]\n",
      "  0%|          | 2/579 [00:00<00:55, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 73.15068493150685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:55<00:00, 10.42it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:03, 18.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 310.48247000947595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 18.01it/s]\n",
      "  0%|          | 2/579 [00:00<00:54, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 73.28767123287672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:58<00:00,  9.98it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:03, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 304.6229900084436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 16.26it/s]\n",
      "  0%|          | 2/579 [00:00<00:54, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.93150684931507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:59<00:00,  9.72it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:05, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 292.33895471319556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.18it/s]\n",
      "  0%|          | 1/579 [00:00<00:58,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 72.32876712328768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:58<00:00,  9.93it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:04, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 293.5813474059105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.59it/s]\n",
      "  0%|          | 1/579 [00:00<00:59,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 75.75342465753425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:58<00:00,  9.90it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:04, 17.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 287.6773977652192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.43it/s]\n",
      "  0%|          | 1/579 [00:00<01:03,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 75.61643835616438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:59<00:00,  9.74it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:05, 13.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 280.64492953475565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 16.52it/s]\n",
      "  0%|          | 1/579 [00:00<01:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 75.75342465753425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:59<00:00,  9.70it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:04, 17.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 269.2567945048213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.05it/s]\n",
      "  0%|          | 1/579 [00:00<01:08,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 73.28767123287672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:57<00:00, 10.07it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:05, 13.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 268.40229304879904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.22it/s]\n",
      "  0%|          | 1/579 [00:00<01:00,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 75.75342465753425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:58<00:00,  9.97it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:04, 14.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 263.3012895239517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.42it/s]\n",
      "  0%|          | 1/579 [00:00<01:06,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.38356164383562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:57<00:00, 10.15it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:03, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 257.87953903432935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.09it/s]\n",
      "  0%|          | 1/579 [00:00<00:58,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 75.34246575342466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [00:58<00:00,  9.96it/s]\n",
      "  3%|▎         | 2/73 [00:00<00:05, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 251.42889169976115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:04<00:00, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 75.89041095890411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    random.shuffle(train_data)\n",
    "    total_loss = 0\n",
    "    for n in tqdm(range(num_train_batches)):\n",
    "        datapoints = train_data[n * batch_size:(n + 1) * batch_size]\n",
    "        X, Y, lengths = datapoints_to_batch(datapoints, max_len, senti_dict)\n",
    "        loss = train_on_batch(model, criterion, optimizer, X, Y, lengths)\n",
    "        total_loss += loss\n",
    "    print(f\"loss: {total_loss}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for n in tqdm(range(num_test_batches)):\n",
    "            datapoints = test_data[n * batch_size:(n + 1) * batch_size]\n",
    "            X, Y, lengths = datapoints_to_batch(datapoints, max_len, senti_dict)\n",
    "            result, _ = predict_on_batch(model, X, Y, lengths)\n",
    "            total += batch_size\n",
    "            correct += result\n",
    "        acc = correct/total * 100\n",
    "        print(f\"acc: {acc}\")\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model, \"lstm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (lstm): LSTM(304, 20, batch_first=True, bidirectional=True)\n",
       "  (dense): Linear(in_features=40, out_features=3, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"lstm.model\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X, Y, lengths = datapoints_to_batch(test_data, max_len, senti_dict)\n",
    "_, pred = predict_on_batch(model, X, Y, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76       209\n",
      "           1       0.71      0.89      0.79       271\n",
      "           2       0.84      0.66      0.74       243\n",
      "\n",
      "    accuracy                           0.77       723\n",
      "   macro avg       0.78      0.76      0.76       723\n",
      "weighted avg       0.78      0.77      0.76       723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
